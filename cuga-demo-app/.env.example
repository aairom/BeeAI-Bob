# CUGA Demo Application - Environment Variables Template
# Copy this file to .env and fill in your actual values

# ============================================================================
# LLM Provider Configuration (Choose ONE)
# ============================================================================

# Option 1: OpenAI
# ----------------
OPENAI_API_KEY=your-openai-api-key-here
AGENT_SETTING_CONFIG="settings.openai.toml"
# Optional overrides:
# MODEL_NAME=gpt-4o
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_API_VERSION=2024-08-06

# Option 2: IBM WatsonX
# ---------------------
# WATSONX_API_KEY=your-watsonx-api-key
# WATSONX_PROJECT_ID=your-project-id
# WATSONX_URL=https://us-south.ml.cloud.ibm.com
# AGENT_SETTING_CONFIG="settings.watsonx.toml"
# MODEL_NAME=meta-llama/llama-4-maverick-17b-128e-instruct-fp8

# Option 3: Azure OpenAI
# ----------------------
# AZURE_OPENAI_API_KEY=your-azure-api-key
# AZURE_OPENAI_ENDPOINT=your-azure-endpoint
# OPENAI_API_VERSION=2024-08-01-preview
# AGENT_SETTING_CONFIG="settings.azure.toml"

# Option 4: OpenRouter
# --------------------
# OPENROUTER_API_KEY=your-openrouter-api-key
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
# AGENT_SETTING_CONFIG="settings.openrouter.toml"
# MODEL_NAME=openai/gpt-4o

# Option 5: LiteLLM (via OpenAI config)
# -------------------------------------
# OPENAI_API_KEY=your-api-key
# AGENT_SETTING_CONFIG="settings.openai.toml"
# MODEL_NAME=Azure/gpt-4o
# OPENAI_BASE_URL=https://your-litellm-endpoint.com
# OPENAI_API_VERSION=2024-08-06

# ============================================================================
# Application Settings
# ============================================================================

# Application mode
APP_MODE=development  # development, production

# Logging level
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL

# ============================================================================
# Optional: Sandbox Configuration
# ============================================================================

# Enable Docker/Podman sandbox for secure code execution
# ENABLE_SANDBOX=false
# SANDBOX_RUNTIME=docker  # docker or podman

# ============================================================================
# Optional: Memory Configuration
# ============================================================================

# Enable memory for learning from past executions
# ENABLE_MEMORY=false
# MEMORY_BACKEND=local  # local, redis, etc.

# ============================================================================
# Optional: Custom Tool Configuration
# ============================================================================

# Add your custom API endpoints here
# CUSTOM_API_ENDPOINT=https://api.example.com
# CUSTOM_API_KEY=your-custom-api-key

# ============================================================================
# Optional: Demo Configuration
# ============================================================================

# Starting URL for hybrid mode demos
# DEMO_START_URL=https://opensource-demo.orangehrmlive.com/web/index.php/auth/login

# ============================================================================
# Optional: Advanced Settings
# ============================================================================

# Request timeout (seconds)
# REQUEST_TIMEOUT=30

# Max retries for failed requests
# MAX_RETRIES=3

# Enable debug mode
# DEBUG=false